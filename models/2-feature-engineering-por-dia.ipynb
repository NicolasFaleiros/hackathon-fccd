{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import entropy\n",
    "from pandas import Timedelta\n",
    "from unidecode import unidecode\n",
    "from scipy.stats import entropy\n",
    "import gc\n",
    "import time\n",
    "\n",
    "# # Encoder para tratamento de variáveis categóricas\n",
    "import category_encoders as ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.enable()\n",
    "def calcular_entropia(lista):\n",
    "    valores, contagem = np.unique(lista, return_counts=True)\n",
    "    return entropy(contagem, base=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "dia = 'arquivos_base\\df_lances_dia_3'\n",
    "diretorio_destino = 'arquivos_treino_teste\\Formato_por_dia\\df_lances_dia3.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(dia)\n",
    "df = df.fillna('Desconhecido')\n",
    "# df = df[df.groupby('id_participante')['id_lance'].transform(lambda x: x.count()) >= 2]\n",
    "# df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculos de entropia\n",
    "\n",
    "# Convert relevant columns to strings\n",
    "df['ip'] = df['ip'].astype(str)\n",
    "df['pais'] = df['pais'].astype(str)\n",
    "df['dispositivo'] = df['dispositivo'].astype(str)\n",
    "df['url'] = df['url'].astype(str)\n",
    "\n",
    "# Calculos de entropia\n",
    "# Entropia IP\n",
    "df_entropia = df.groupby('id_participante')['ip'].apply(calcular_entropia).reset_index()\n",
    "df_entropia.columns = ['id_participante', 'entropia_ip']\n",
    "df = df.merge(df_entropia, on='id_participante', how='left')\n",
    "\n",
    "# Entropia País\n",
    "df_entropia = df.groupby('id_participante')['pais'].apply(calcular_entropia).reset_index()\n",
    "df_entropia.columns = ['id_participante', 'entropia_pais']\n",
    "df = df.merge(df_entropia, on='id_participante', how='left')\n",
    "\n",
    "# Entropia Dispositivo\n",
    "df_entropia = df.groupby('id_participante')['dispositivo'].apply(calcular_entropia).reset_index()\n",
    "df_entropia.columns = ['id_participante', 'entropia_dispositivo']\n",
    "df = df.merge(df_entropia, on='id_participante', how='left')\n",
    "\n",
    "# Entropia URL\n",
    "df_entropia = df.groupby('id_participante')['url'].apply(calcular_entropia).reset_index()\n",
    "df_entropia.columns = ['id_participante', 'entropia_url']\n",
    "df = df.merge(df_entropia, on='id_participante', how='left')\n",
    "\n",
    "# Entropia Pais - IP\n",
    "df['pais_ip'] = df['pais'] + '_' + df['ip']\n",
    "df_entropia = df.groupby('id_participante')['pais_ip'].apply(calcular_entropia).reset_index()\n",
    "df_entropia.columns = ['id_participante', 'entropia_pais_ip']\n",
    "df = df.merge(df_entropia, on='id_participante', how='left')\n",
    "\n",
    "# Entropia Dispositivo - IP\n",
    "df['dispositivo_ip'] = df['dispositivo'] + '_' + df['ip']\n",
    "df_entropia = df.groupby('id_participante')['dispositivo_ip'].apply(calcular_entropia).reset_index()\n",
    "df_entropia.columns = ['id_participante', 'entropia_dispositivo_ip']\n",
    "df = df.merge(df_entropia, on='id_participante', how='left')\n",
    "\n",
    "# Entropia Dispositivo - URL\n",
    "df['dispositivo_url'] = df['dispositivo'] + '_' + df['url']\n",
    "df_entropia = df.groupby('id_participante')['dispositivo_url'].apply(calcular_entropia).reset_index()\n",
    "df_entropia.columns = ['id_participante', 'entropia_dispositivo_url']\n",
    "df = df.merge(df_entropia, on='id_participante', how='left')\n",
    "\n",
    "# Entropia Dispositivo - Pais\n",
    "df['dispositivo_pais'] = df['dispositivo'] + '_' + df['pais']\n",
    "df_entropia = df.groupby('id_participante')['dispositivo_pais'].apply(calcular_entropia).reset_index()\n",
    "df_entropia.columns = ['id_participante', 'entropia_dispositivo_pais']\n",
    "df = df.merge(df_entropia, on='id_participante', how='left')\n",
    "\n",
    "# Entropia URL - IP\n",
    "df['url_pais'] = df['url'] + '_' + df['pais']\n",
    "df_entropia = df.groupby('id_participante')['url_pais'].apply(calcular_entropia).reset_index()\n",
    "df_entropia.columns = ['id_participante', 'entropia_url_pais']\n",
    "df = df.merge(df_entropia, on='id_participante', how='left')\n",
    "\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_entropia = df.drop(columns = ['dispositivo', 'pais', 'ip', 'url', 'pais_ip', 'dispositivo_ip', 'dispositivo_url', 'dispositivo_pais', 'url_pais', 'id_lance', 'leilao', 'mercadoria', 'tempo'])\n",
    "df_entropia = df_entropia.drop_duplicates(subset='id_participante', keep='first')\n",
    "df_entropia = df_entropia.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Tempo #######\n",
    "\n",
    "\n",
    "df = pd.read_csv(dia)\n",
    "df = df.fillna('Desconhecido')\n",
    "# df = df[df.groupby('id_participante')['id_lance'].transform(lambda x: x.count()) >= 2]\n",
    "# df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "um_dia = 63663157894736\n",
    "uma_hora = um_dia / 24\n",
    "um_minuto = uma_hora // 60\n",
    "um_segundo = um_minuto / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definindo a janela de tempo (em minutos)\n",
    "window_size = int(30 * um_minuto)  # Exemplo: janela de 30 minutos\n",
    "\n",
    "\n",
    "# Função para calcular a densidade de lances\n",
    "def calcular_densidade_lances(dados, window_size):\n",
    "    dados = dados.sort_values(by='tempo')\n",
    "    dados['densidade'] = dados['tempo'].rolling(window=window_size, min_periods=1).count()\n",
    "    return dados\n",
    "\n",
    "df = calcular_densidade_lances(df, window_size)\n",
    "\n",
    "# Identificar o pico de lances por leilão\n",
    "df['pico'] = df.groupby('leilao')['densidade'].transform('max') == df['densidade']\n",
    "\n",
    "# Otimização para verificar se um lance está no pico (retornando 0 ou 1)\n",
    "def verificar_lance_no_pico(df, window_size):\n",
    "    pico_lances = df[df['pico']].groupby('leilao')['tempo'].first().reset_index()\n",
    "    pico_lances['intervalo_inicio'] = pico_lances['tempo'] - window_size // 2\n",
    "    pico_lances['intervalo_fim'] = pico_lances['tempo'] + window_size // 2\n",
    "    \n",
    "    df = df.merge(pico_lances[['leilao', 'intervalo_inicio', 'intervalo_fim']], on='leilao', how='left')\n",
    "    df['lance_no_pico'] = (df['tempo'] >= df['intervalo_inicio']) & (df['tempo'] <= df['intervalo_fim'])\n",
    "    df['lance_no_pico'] = df['lance_no_pico'].astype(int)\n",
    "    df.drop(columns=['intervalo_inicio', 'intervalo_fim'], inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Aplicar a função a todos os lances\n",
    "df = verificar_lance_no_pico(df, window_size)\n",
    "df = df.drop(columns=['densidade', 'pico'], axis = 1)\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calcular a quantidade de lances dentro e fora do pico por participante\n",
    "df['qtde_lances_pico'] = df.groupby('id_participante')['lance_no_pico'].transform('sum')\n",
    "df['qtde_lances_fora_pico'] = df.groupby('id_participante')['lance_no_pico'].transform(lambda x: (x == 0).sum())\n",
    "\n",
    "# Calcular a porcentagem de lances no pico e fora dele\n",
    "df['porcentagem_lances_pico'] = df['qtde_lances_pico'] / (df['qtde_lances_pico'] + df['qtde_lances_fora_pico'])\n",
    "df['porcentagem_lances_fora_pico'] = 1 - df['porcentagem_lances_pico']\n",
    "\n",
    "# Remover a coluna lance_no_pico\n",
    "df.drop(columns=['lance_no_pico'], inplace=True)\n",
    "\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_12796\\2867994732.py:15: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  contagem_quartis = df.groupby(['id_participante', 'quartil_tempo']).size().unstack(fill_value=0)\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_12796\\2867994732.py:18: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  contagem_quartis = df.groupby(['id_participante', 'quartil_tempo']).size().unstack(fill_value=0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fazer tratamento de tempo. Quartis que o usuário faz lances e o restante\n",
    "\n",
    "# Calcular o tempo do leilao - Tempo Início e Tempo fim\n",
    "tempos_leiloes = df.groupby(['leilao'])['tempo'].agg(['min', 'max']).reset_index()\n",
    "tempos_leiloes.columns = ['leilao', 'inicio_leilao', 'fim_leilao']\n",
    "\n",
    "# Passo 1: Juntar df e tempos_leiloes pelo código do leilão\n",
    "df = df.merge(tempos_leiloes, on='leilao', how='left')\n",
    "\n",
    "# Passo 2: Calcular a posição do tempo do lance em relação ao intervalo de tempo do leilão\n",
    "df['posicao_relativa'] = (df['tempo'] - df['inicio_leilao']) / (df['fim_leilao'] - df['inicio_leilao'])\n",
    "\n",
    "# Passo 3: Classificar a posição relativa em quartis\n",
    "df['quartil_tempo'] = pd.qcut(df['posicao_relativa'], 4, labels=[1, 2, 3, 4])\n",
    "contagem_quartis = df.groupby(['id_participante', 'quartil_tempo']).size().unstack(fill_value=0)\n",
    "\n",
    "# Passo 4: Contar a distribuição dos quartis para cada participante\n",
    "contagem_quartis = df.groupby(['id_participante', 'quartil_tempo']).size().unstack(fill_value=0)\n",
    "\n",
    "\n",
    "# Renomear as colunas para facilitar a junção com df\n",
    "contagem_quartis.columns = ['qtde_lances_quartil_1', 'qtde_lances_quartil_2', 'qtde_lances_quartil_3', 'qtde_lances_quartil_4']\n",
    "\n",
    "contagem_quartis['soma_lances'] = contagem_quartis.sum(axis=1)\n",
    "contagem_quartis['porcentagem_lances_quartil_1'] = contagem_quartis['qtde_lances_quartil_1'] / contagem_quartis['soma_lances']\n",
    "contagem_quartis['porcentagem_lances_quartil_2'] = contagem_quartis['qtde_lances_quartil_2'] / contagem_quartis['soma_lances']\n",
    "contagem_quartis['porcentagem_lances_quartil_3'] = contagem_quartis['qtde_lances_quartil_3'] / contagem_quartis['soma_lances']\n",
    "contagem_quartis['porcentagem_lances_quartil_4'] = contagem_quartis['qtde_lances_quartil_4'] / contagem_quartis['soma_lances']\n",
    "\n",
    "\n",
    "contagem_quartis['std_lances_por_quartil'] = contagem_quartis.iloc[:, :-1].std(axis=1)\n",
    "\n",
    "\n",
    "# Resetar o índice para transformar contagem_quartis em um DataFrame regular\n",
    "contagem_quartis = contagem_quartis.reset_index()\n",
    "contagem_quartis.drop(columns=['soma_lances'], inplace=True)\n",
    "\n",
    "# Adicionar as colunas de contagem de quartis ao df através de um merge\n",
    "df = df.merge(contagem_quartis, on='id_participante', how='left')\n",
    "\n",
    "\n",
    "## Calculando métricas de diferença de tempo\n",
    "\n",
    "# Calcular a diferença de tempo entre lances\n",
    "\n",
    "df = df.sort_values(['id_participante', 'tempo', 'id_lance', 'leilao'])\n",
    "dif_tempo = df.groupby('id_participante')[['tempo']].diff()\n",
    "df['diferenca_tempo'] = dif_tempo\n",
    "\n",
    "# Métricas para diferença de tempo de lances do participante // depois fazer dif de tempo por leilao\n",
    "\n",
    "df['media_diftempo_porusuario'] = df.groupby(['id_participante'])['diferenca_tempo'].transform('mean')\n",
    "df['mediana_difs_tempo_participante'] = df.groupby('id_participante')['diferenca_tempo'].transform('median')\n",
    "\n",
    "# Calcular desvio padrão da diferença de tempo entre lances\n",
    "\n",
    "# Passo 1: Calcular a diferença quadrada entre lances por dispositivo e a média de lances de por dispositivo\n",
    "df['diferenca_quadrada'] = (df['diferenca_tempo'] - df['media_diftempo_porusuario'])**2\n",
    "# Passo 2: Agrupar novamente pelo id_participante e calcular a média dos quadrados das diferenças\n",
    "desvios_quadraticos_medios = df.groupby('id_participante')['diferenca_quadrada'].mean()\n",
    "# Passo 3: Tirar a raiz quadrada dessa média\n",
    "std_difstempo_porlance = np.sqrt(desvios_quadraticos_medios)\n",
    "std_difstempo_dict = std_difstempo_porlance.to_dict()\n",
    "\n",
    "# Passo 4: Mapeando o desvio padrão correspondente para cada id_participante em df\n",
    "df['std_difstempo_porlance'] = df['id_participante'].map(std_difstempo_dict)\n",
    "\n",
    "# Tem lances ao mesmo tempo\n",
    "\n",
    "# Passo 1: Contar quantos lances por participante ocorrem em cada tempo\n",
    "df['qtde_lances_simultaneos'] = df.groupby(['id_participante', 'tempo'])['tempo'].transform('count')\n",
    "\n",
    "# Passo 2: Criar a coluna 'tem_lance_simultaneo'\n",
    "df['tem_lance_simultaneo'] = df['qtde_lances_simultaneos'].apply(lambda x: 1 if x > 1 else 0)\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id_lance                              0\n",
       "id_participante                       0\n",
       "leilao                                0\n",
       "mercadoria                            0\n",
       "dispositivo                           0\n",
       "tempo                                 0\n",
       "pais                                  0\n",
       "ip                                    0\n",
       "url                                   0\n",
       "qtde_lances_pico                      0\n",
       "qtde_lances_fora_pico                 0\n",
       "porcentagem_lances_pico               0\n",
       "porcentagem_lances_fora_pico          0\n",
       "inicio_leilao                         0\n",
       "fim_leilao                            0\n",
       "posicao_relativa                    577\n",
       "quartil_tempo                       577\n",
       "qtde_lances_quartil_1                 0\n",
       "qtde_lances_quartil_2                 0\n",
       "qtde_lances_quartil_3                 0\n",
       "qtde_lances_quartil_4                 0\n",
       "porcentagem_lances_quartil_1          1\n",
       "porcentagem_lances_quartil_2          1\n",
       "porcentagem_lances_quartil_3          1\n",
       "porcentagem_lances_quartil_4          1\n",
       "std_lances_por_quartil                0\n",
       "diferenca_tempo                    2954\n",
       "media_diftempo_porusuario           471\n",
       "mediana_difs_tempo_participante     471\n",
       "diferenca_quadrada                 2954\n",
       "std_difstempo_porlance              471\n",
       "qtde_lances_simultaneos               0\n",
       "tem_lance_simultaneo                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id_participante                      0\n",
       "qtde_lances_pico                     0\n",
       "qtde_lances_fora_pico                0\n",
       "porcentagem_lances_pico              0\n",
       "porcentagem_lances_fora_pico         0\n",
       "porcentagem_lances_quartil_1         1\n",
       "porcentagem_lances_quartil_2         1\n",
       "porcentagem_lances_quartil_3         1\n",
       "porcentagem_lances_quartil_4         1\n",
       "std_lances_por_quartil               0\n",
       "media_diftempo_porusuario          471\n",
       "mediana_difs_tempo_participante    471\n",
       "std_difstempo_porlance             471\n",
       "qtde_lances_simultaneos              0\n",
       "tem_lance_simultaneo                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tempo = df.drop_duplicates(subset='id_participante', keep='first')\n",
    "\n",
    "colunas_para_dropar = ['id_lance', 'leilao', 'mercadoria', 'dispositivo', 'tempo', 'pais', 'ip', 'url', 'inicio_leilao', 'fim_leilao', 'posicao_relativa', 'quartil_tempo',\n",
    " 'qtde_lances_quartil_1', 'qtde_lances_quartil_2', 'qtde_lances_quartil_3', 'qtde_lances_quartil_4', 'diferenca_tempo', 'diferenca_quadrada']\n",
    "\n",
    "df_tempo = df_tempo.drop(columns=colunas_para_dropar, axis = 1)\n",
    "df_tempo = df_tempo.reset_index(drop=True)\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "df_tempo.isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### Feature Engineering Geral #######\n",
    "\n",
    "df = pd.read_csv(dia)\n",
    "df = df.fillna('Desconhecido')\n",
    "# df = df[df.groupby('id_participante')['id_lance'].transform(lambda x: x.count()) >= 2]\n",
    "# df = df.reset_index(drop=True)\n",
    "\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inicio Lances\n",
      "Fim Lances - 6.485780954360962 segundos\n",
      "Inicio Mercadorias\n"
     ]
    }
   ],
   "source": [
    "# Lances \n",
    "print('Inicio Lances')\n",
    "inicio = time.time()\n",
    "\n",
    "df['total_lances_participante'] = df.groupby(['id_participante'])['id_lance'].transform('count')\n",
    "df['leiloes_participados'] = df.groupby(['id_participante'])['leilao'].transform('nunique')\n",
    "df['total_lances_nesseleilao'] = df.groupby(['id_participante', 'leilao'])['id_lance'].transform('count')\n",
    "df['media_lances_porleilao'] = df.groupby(['id_participante'])['total_lances_nesseleilao'].transform('mean')\n",
    "df['max_lances_leilao'] = df.groupby(['id_participante'])['total_lances_nesseleilao'].transform('max')\n",
    "\n",
    "## Calculando mediana de lances por leilão\n",
    "# Agrupando e transformando as listas de lances por leilão em cada grupo\n",
    "valores_mediana_porleilao = df.groupby(['id_participante'])['total_lances_nesseleilao'].agg(lambda x: np.median(x.tolist())).reset_index()\n",
    "# Renomeando a coluna da mediana\n",
    "valores_mediana_porleilao.columns = ['id_participante', 'mediana_lances_porleilao']\n",
    "# Mesclando com o dataframe original\n",
    "df = pd.merge(df, valores_mediana_porleilao, on='id_participante', how='left')\n",
    "\n",
    "\n",
    "# Calcular desvio padrão de lances por leilão\n",
    "# Passo 1: Calcular a diferença quadrada entre lances do leilao e a média \n",
    "df['diferenca_quadrada'] = (df['total_lances_nesseleilao'] - df['media_lances_porleilao'])**2\n",
    "# Passo 2: Agrupar novamente pelo id_participante e calcular a média dos quadrados das diferenças\n",
    "desvios_quadraticos_medios = df.groupby('id_participante')['diferenca_quadrada'].mean()\n",
    "# Passo 3: Tirar a raiz quadrada dessa média\n",
    "std_lances_porleilao = np.sqrt(desvios_quadraticos_medios)\n",
    "# Passo 4: Mapeando o desvio padrão correspondente para cada id_participante em df\n",
    "df['std_lances_porleilao'] = df['id_participante'].map(std_lances_porleilao)\n",
    "df = df.drop(columns = 'diferenca_quadrada', axis = 1)\n",
    "\n",
    "\n",
    "fim = time.time()\n",
    "print(f'Fim Lances - {fim - inicio} segundos')\n",
    "\n",
    "\n",
    "print('Inicio Mercadorias')\n",
    "inicio = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fim Mercadorias - 20.95551061630249 segundos\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mercadoria\n",
    "df['qtde_mercadorias_participante'] = df.groupby(['id_participante'])['mercadoria'].transform('nunique')\n",
    "\n",
    "# Loop para quantidade de artigos esportivos:\n",
    "lista_mercadorias = ['artigos esportivos', 'joias', 'móveis',\n",
    "       'equipamentos de escritório', 'bens domésticos', 'livros e música',\n",
    "       'computadores', 'peças de automóveis', 'vestuário']\n",
    "\n",
    "for m in lista_mercadorias:\n",
    "    df_artigos_esportivos = df[df['mercadoria'] == m]\n",
    "    contagem_lances = df_artigos_esportivos.groupby('id_participante')['id_lance'].count()\n",
    "    nome_coluna = 'qtde_lance_' + m\n",
    "    df[nome_coluna] = df['id_participante'].map(contagem_lances).fillna(0).astype(int)\n",
    "\n",
    "# 2. OneHotEncoder na variável 'mercadoria'\n",
    "encoder = ce.OneHotEncoder(cols=['mercadoria'], use_cat_names=True)\n",
    "mercadoria_encoded = encoder.fit_transform(df)\n",
    "\n",
    "mercadoria_encoded_selected = mercadoria_encoded[['id_participante'] + [col for col in mercadoria_encoded.columns if col.startswith('mercadoria_')]]\n",
    "\n",
    "# 3. Agregar os resultados para cada 'id_participante'\n",
    "result_df = mercadoria_encoded_selected.groupby('id_participante').max().reset_index()\n",
    "\n",
    "# 4. Fazer o merge dos resultados agregados com o DataFrame original df\n",
    "df = df.merge(result_df, on='id_participante', how='left')\n",
    "\n",
    "fim = time.time()\n",
    "print(f'Fim Mercadorias - {fim - inicio} segundos')\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inicio Dispositivo\n",
      "Fim dispositivos - 37.538708448410034 segundos\n"
     ]
    }
   ],
   "source": [
    "# Dispositivo\n",
    "\n",
    "print('Inicio Dispositivo')\n",
    "inicio = time.time()\n",
    "\n",
    "df['total_dispositivos_participante'] = df.groupby(['id_participante'])['dispositivo'].transform('nunique')\n",
    "\n",
    "# Lances por dispositivo\n",
    "\n",
    "df['dispositivos_duplicados'] = df.groupby('id_participante')['dispositivo'].transform(lambda x: x.duplicated(keep=False).sum())\n",
    "df['total_lances_pordispositivo'] = df.groupby(['id_participante', 'dispositivo'])['id_lance'].transform('nunique')\n",
    "df['max_lances_pordispositivo'] = df.groupby(['id_participante'])['total_lances_pordispositivo'].transform('max')\n",
    "df['media_lances_pordispositivo'] = df.groupby(['id_participante'])['total_lances_pordispositivo'].transform('mean')\n",
    "\n",
    "## Calculando mediana de lances por dispositivo\n",
    "# Agrupando e transformando as listas de lances por por dispositivo em cada grupo\n",
    "valores_mediana_lances_pordispositivo = df.groupby(['id_participante'])['total_lances_pordispositivo'].agg(lambda x: np.median(x.tolist())).reset_index()\n",
    "# Renomeando a coluna da mediana\n",
    "valores_mediana_lances_pordispositivo.columns = ['id_participante', 'mediana_lances_pordispositivo']\n",
    "\n",
    "# Mesclando com o dataframe original\n",
    "df = pd.merge(df, valores_mediana_lances_pordispositivo, on='id_participante', how='left')\n",
    "\n",
    "# Calcular desvio padrão de lances por dispositivo\n",
    "\n",
    "# Passo 1: Calcular a diferença quadrada entre lances por dispositivo e a média de lances de por dispositivo\n",
    "df['diferenca_quadrada'] = (df['total_lances_pordispositivo'] - df['media_lances_pordispositivo'])**2\n",
    "# Passo 2: Agrupar novamente pelo id_participante e calcular a média dos quadrados das diferenças\n",
    "desvios_quadraticos_medios = df.groupby('id_participante')['diferenca_quadrada'].mean()\n",
    "# Passo 3: Tirar a raiz quadrada dessa média\n",
    "std_lances_porleilao = np.sqrt(desvios_quadraticos_medios)\n",
    "# Passo 4: Mapeando o desvio padrão correspondente para cada id_participante em df\n",
    "df['std_lances_pordispositivo'] = df['id_participante'].map(std_lances_porleilao)\n",
    "df = df.drop(columns = 'diferenca_quadrada', axis = 1)\n",
    "\n",
    "\n",
    "# Dispositivos por leilão\n",
    "\n",
    "df['total_dispositivos_porleilao'] = df.groupby(['id_participante', 'leilao'])['dispositivo'].transform('nunique')\n",
    "df['max_dispositivos_porleilao'] = df.groupby(['id_participante'])['total_dispositivos_porleilao'].transform('max')\n",
    "df['media_dispositivos_porleilao'] = df.groupby(['id_participante'])['total_lances_pordispositivo'].transform('mean')\n",
    "\n",
    "## Calculando mediana dispositivos por leilão\n",
    "# Agrupando e transformando as listas de dispositivo por leilão em cada grupo\n",
    "valores_mediana_dispositivo_porleilao = df.groupby(['id_participante'])['total_dispositivos_porleilao'].agg(lambda x: np.median(x.tolist())).reset_index()\n",
    "# Renomeando a coluna da mediana\n",
    "valores_mediana_dispositivo_porleilao.columns = ['id_participante', 'mediana_dispositivo_porleilao']\n",
    "# Mesclando com o dataframe original\n",
    "df = pd.merge(df, valores_mediana_dispositivo_porleilao, on='id_participante', how='left')\n",
    "\n",
    "# Calcular desvio padrão de dispositivos por leilão\n",
    "\n",
    "# Passo 1: Calcular a diferença quadrada entre lances por dispositivo e a média de lances de por dispositivo\n",
    "df['diferenca_quadrada'] = (df['total_dispositivos_porleilao'] - df['media_dispositivos_porleilao'])**2\n",
    "# Passo 2: Agrupar novamente pelo id_participante e calcular a média dos quadrados das diferenças\n",
    "desvios_quadraticos_medios = df.groupby('id_participante')['diferenca_quadrada'].mean()\n",
    "# Passo 3: Tirar a raiz quadrada dessa média\n",
    "std_lances_porleilao = np.sqrt(desvios_quadraticos_medios)\n",
    "# Passo 4: Mapeando o desvio padrão correspondente para cada id_participante em df\n",
    "df['std_dispositivos_porleilao'] = df['id_participante'].map(std_lances_porleilao)\n",
    "df = df.drop(columns = 'diferenca_quadrada', axis = 1)\n",
    "\n",
    "\n",
    "# Dispositivos por IP\n",
    "\n",
    "df['total_dispositivos_porip'] = df.groupby(['id_participante', 'ip'])['dispositivo'].transform('nunique')\n",
    "df['max_dispositivos_porip'] = df.groupby(['id_participante'])['total_dispositivos_porip'].transform('max')\n",
    "df['media_dispositivos_porip'] = df.groupby(['id_participante'])['total_dispositivos_porip'].transform('mean')\n",
    "\n",
    "## Calculando mediana dispositivos por leilão\n",
    "# Agrupando e transformando as listas de dispositivo por leilão em cada grupo\n",
    "valores_mediana_dispositivo_porip = df.groupby(['id_participante'])['total_dispositivos_porip'].agg(lambda x: np.median(x.tolist())).reset_index()\n",
    "# Renomeando a coluna da mediana\n",
    "valores_mediana_dispositivo_porip.columns = ['id_participante', 'mediana_dispositivo_porip']\n",
    "# Mesclando com o dataframe original\n",
    "df = pd.merge(df, valores_mediana_dispositivo_porip, on='id_participante', how='left')\n",
    "\n",
    "# Calcular desvio padrão de dispositivos por ip\n",
    "\n",
    "# Passo 1: Calcular a diferença quadrada entre lances por dispositivo e a média de lances de por dispositivo\n",
    "df['diferenca_quadrada'] = (df['total_dispositivos_porip'] - df['media_dispositivos_porip'])**2\n",
    "# Passo 2: Agrupar novamente pelo id_participante e calcular a média dos quadrados das diferenças\n",
    "desvios_quadraticos_medios = df.groupby('id_participante')['diferenca_quadrada'].mean()\n",
    "# Passo 3: Tirar a raiz quadrada dessa média\n",
    "std_dispositivos_porip = np.sqrt(desvios_quadraticos_medios)\n",
    "# Passo 4: Mapeando o desvio padrão correspondente para cada id_participante em df\n",
    "df['std_dispositivos_porip'] = df['id_participante'].map(std_dispositivos_porip)\n",
    "df = df.drop(columns = 'diferenca_quadrada', axis = 1)\n",
    "\n",
    "\n",
    "# Dispositivos por URL\n",
    "\n",
    "df['total_dispositivos_porurl'] = df.groupby(['id_participante', 'url'])['dispositivo'].transform('nunique')\n",
    "df['max_dispositivos_porurl'] = df.groupby(['id_participante'])['total_dispositivos_porurl'].transform('max')\n",
    "df['media_dispositivos_porurl'] = df.groupby(['id_participante'])['total_dispositivos_porurl'].transform('mean')\n",
    "\n",
    "## Calculando mediana Dispositivos por URL\n",
    "# Agrupando e transformando as listas de dispositivo por leilão em cada grupo\n",
    "valores_mediana_dispositivo_porurl = df.groupby(['id_participante'])['total_dispositivos_porurl'].agg(lambda x: np.median(x.tolist())).reset_index()\n",
    "# Renomeando a coluna da mediana\n",
    "valores_mediana_dispositivo_porurl.columns = ['id_participante', 'mediana_dispositivo_porurl']\n",
    "# Mesclando com o dataframe original\n",
    "df = pd.merge(df, valores_mediana_dispositivo_porurl, on='id_participante', how='left')\n",
    "\n",
    "# Calcular desvio padrão de Dispositivos por URL\n",
    "\n",
    "# Passo 1: Calcular a diferença quadrada entre lances por dispositivo e a média de lances de por dispositivo\n",
    "df['diferenca_quadrada'] = (df['total_dispositivos_porurl'] - df['media_dispositivos_porurl'])**2\n",
    "# Passo 2: Agrupar novamente pelo id_participante e calcular a média dos quadrados das diferenças\n",
    "desvios_quadraticos_medios = df.groupby('id_participante')['diferenca_quadrada'].mean()\n",
    "# Passo 3: Tirar a raiz quadrada dessa média\n",
    "std_dispositivos_porurl = np.sqrt(desvios_quadraticos_medios)\n",
    "# Passo 4: Mapeando o desvio padrão correspondente para cada id_participante em df\n",
    "df['std_dispositivos_porurl'] = df['id_participante'].map(std_dispositivos_porurl)\n",
    "df = df.drop(columns = 'diferenca_quadrada', axis = 1)\n",
    "\n",
    "\n",
    "fim = time.time()\n",
    "print(f'Fim dispositivos - {fim - inicio} segundos')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inicio IPs\n",
      "Fim IPs - 53.38318610191345 segundos\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# IPs\n",
    "\n",
    "print('Inicio IPs')\n",
    "inicio = time.time()\n",
    "\n",
    "df['total_ips_participante'] = df.groupby(['id_participante'])['ip'].transform('nunique')\n",
    "\n",
    "# IPs por leilão\n",
    "\n",
    "df['ips_duplicados'] = df.groupby('id_participante')['ip'].transform(lambda x: x.duplicated(keep=False).sum())\n",
    "df['ips_por_leilao'] = df.groupby(['id_participante', 'leilao'])['ip'].transform('nunique')\n",
    "df['max_ips_porleilao'] = df.groupby(['id_participante'])['ips_por_leilao'].transform('max')\n",
    "df['media_ips_porleilao'] = df.groupby(['id_participante'])['ips_por_leilao'].transform('mean')\n",
    "\n",
    "## Calculando mediana de IPs por leilao\n",
    "# Agrupando e transformando as listas de lances por por dispositivo em cada grupo\n",
    "valores_mediana_ips_porleilao = df.groupby(['id_participante'])['ips_por_leilao'].agg(lambda x: np.median(x.tolist())).reset_index()\n",
    "# Renomeando a coluna da mediana\n",
    "valores_mediana_ips_porleilao.columns = ['id_participante', 'mediana_ips_porleilao']\n",
    "# Mesclando com o dataframe original\n",
    "df = pd.merge(df, valores_mediana_ips_porleilao, on='id_participante', how='left')\n",
    "\n",
    "# Calcular desvio padrão de IPs por leilão\n",
    "\n",
    "# Passo 1: Calcular a diferença quadrada entre lances por dispositivo e a média de lances de por dispositivo\n",
    "df['diferenca_quadrada'] = (df['ips_por_leilao'] - df['media_ips_porleilao'])**2\n",
    "# Passo 2: Agrupar novamente pelo id_participante e calcular a média dos quadrados das diferenças\n",
    "desvios_quadraticos_medios = df.groupby('id_participante')['diferenca_quadrada'].mean()\n",
    "# Passo 3: Tirar a raiz quadrada dessa média\n",
    "std_ips_porleilao = np.sqrt(desvios_quadraticos_medios)\n",
    "# Passo 4: Mapeando o desvio padrão correspondente para cada id_participante em df\n",
    "df['std_ips_porleilao'] = df['id_participante'].map(std_ips_porleilao)\n",
    "df = df.drop(columns = 'diferenca_quadrada', axis = 1)\n",
    "\n",
    "\n",
    "# Lances por IP\n",
    "\n",
    "df['lances_por_ip'] = df.groupby(['id_participante', 'ip'])['id_lance'].transform('nunique')\n",
    "df['max_lances_porip'] = df.groupby(['id_participante'])['lances_por_ip'].transform('max')\n",
    "df['media_lances_porip'] = df.groupby(['id_participante'])['lances_por_ip'].transform('mean')\n",
    "\n",
    "## Calculando mediana de lances por país\n",
    "# Agrupando e transformando as listas de lances por por dispositivo em cada grupo\n",
    "valores_mediana_lances_porip = df.groupby(['id_participante'])['lances_por_ip'].agg(lambda x: np.median(x.tolist())).reset_index()\n",
    "# Renomeando a coluna da mediana\n",
    "valores_mediana_lances_porip.columns = ['id_participante', 'mediana_lances_porip']\n",
    "# Mesclando com o dataframe original\n",
    "df = pd.merge(df, valores_mediana_lances_porip, on='id_participante', how='left')\n",
    "\n",
    "# Calcular desvio padrão de lances por país\n",
    "\n",
    "# Passo 1: Calcular a diferença quadrada entre lances por dispositivo e a média de lances de por dispositivo\n",
    "df['diferenca_quadrada'] = (df['lances_por_ip'] - df['media_lances_porip'])**2\n",
    "# Passo 2: Agrupar novamente pelo id_participante e calcular a média dos quadrados das diferenças\n",
    "desvios_quadraticos_medios = df.groupby('id_participante')['diferenca_quadrada'].mean()\n",
    "# Passo 3: Tirar a raiz quadrada dessa média\n",
    "std_lances_porip = np.sqrt(desvios_quadraticos_medios)\n",
    "# Passo 4: Mapeando o desvio padrão correspondente para cada id_participante em df\n",
    "df['std_lances_porip'] = df['id_participante'].map(std_lances_porip)\n",
    "df = df.drop(columns = 'diferenca_quadrada', axis = 1)\n",
    "\n",
    "\n",
    "# IPs por dispositivo\n",
    "\n",
    "df['ips_por_dispositivo'] = df.groupby(['id_participante', 'dispositivo'])['ip'].transform('nunique')\n",
    "df['max_ips_pordispositivo'] = df.groupby(['id_participante'])['ips_por_dispositivo'].transform('max')\n",
    "df['media_ips_pordispositivo'] = df.groupby(['id_participante'])['ips_por_dispositivo'].transform('mean')\n",
    "\n",
    "## Calculando mediana de IPs por leilao\n",
    "# Agrupando e transformando as listas de lances por por dispositivo em cada grupo\n",
    "valores_mediana_ips_pordispositivo = df.groupby(['id_participante'])['ips_por_dispositivo'].agg(lambda x: np.median(x.tolist())).reset_index()\n",
    "# Renomeando a coluna da mediana\n",
    "valores_mediana_ips_pordispositivo.columns = ['id_participante', 'mediana_ips_por_dispositivo']\n",
    "# Mesclando com o dataframe original\n",
    "df = pd.merge(df, valores_mediana_ips_pordispositivo, on='id_participante', how='left')\n",
    "\n",
    "# Calcular desvio padrão de IPs por dispositivo\n",
    "\n",
    "# Passo 1: Calcular a diferença quadrada entre lances por dispositivo e a média de lances de por dispositivo\n",
    "df['diferenca_quadrada'] = (df['ips_por_dispositivo'] - df['media_ips_pordispositivo'])**2\n",
    "# Passo 2: Agrupar novamente pelo id_participante e calcular a média dos quadrados das diferenças\n",
    "desvios_quadraticos_medios = df.groupby('id_participante')['diferenca_quadrada'].mean()\n",
    "# Passo 3: Tirar a raiz quadrada dessa média\n",
    "std_ips_pordispositivo = np.sqrt(desvios_quadraticos_medios)\n",
    "# Passo 4: Mapeando o desvio padrão correspondente para cada id_participante em df\n",
    "df['std_ips_pordispositivo'] = df['id_participante'].map(std_ips_pordispositivo)\n",
    "df = df.drop(columns = 'diferenca_quadrada', axis = 1)\n",
    "\n",
    "\n",
    "# IPs por país\n",
    "\n",
    "df['ips_por_pais'] = df.groupby(['id_participante', 'pais'])['ip'].transform('nunique')\n",
    "df['max_ips_porpais'] = df.groupby(['id_participante'])['ips_por_pais'].transform('max')\n",
    "df['media_ips_porpais'] = df.groupby(['id_participante'])['ips_por_pais'].transform('mean')\n",
    "\n",
    "## Calculando mediana de IPs por país\n",
    "# Agrupando e transformando as listas de lances por por dispositivo em cada grupo\n",
    "valores_mediana_ips_porpais = df.groupby(['id_participante'])['ips_por_pais'].agg(lambda x: np.median(x.tolist())).reset_index()\n",
    "# Renomeando a coluna da mediana\n",
    "valores_mediana_ips_porpais.columns = ['id_participante', 'mediana_ips_por_pais']\n",
    "# Mesclando com o dataframe original\n",
    "df = pd.merge(df, valores_mediana_ips_porpais, on='id_participante', how='left')\n",
    "\n",
    "# Calcular desvio padrão de IPs por país\n",
    "\n",
    "# Passo 1: Calcular a diferença quadrada entre lances por dispositivo e a média de lances de por dispositivo\n",
    "df['diferenca_quadrada'] = (df['ips_por_pais'] - df['media_ips_porpais'])**2\n",
    "# Passo 2: Agrupar novamente pelo id_participante e calcular a média dos quadrados das diferenças\n",
    "desvios_quadraticos_medios = df.groupby('id_participante')['diferenca_quadrada'].mean()\n",
    "# Passo 3: Tirar a raiz quadrada dessa média\n",
    "std_ips_porpais = np.sqrt(desvios_quadraticos_medios)\n",
    "# Passo 4: Mapeando o desvio padrão correspondente para cada id_participante em df\n",
    "df['std_ips_porpais'] = df['id_participante'].map(std_ips_porpais)\n",
    "df = df.drop(columns = 'diferenca_quadrada', axis = 1)\n",
    "\n",
    "\n",
    "# IPs por URL\n",
    "\n",
    "df['ips_por_url'] = df.groupby(['id_participante', 'url'])['ip'].transform('nunique')\n",
    "df['max_ips_porurl'] = df.groupby(['id_participante'])['ips_por_url'].transform('max')\n",
    "df['media_ips_porurl'] = df.groupby(['id_participante'])['ips_por_url'].transform('mean')\n",
    "\n",
    "## Calculando mediana de IPs por URL\n",
    "# Agrupando e transformando as listas de lances por por dispositivo em cada grupo\n",
    "valores_mediana_ips_porurl = df.groupby(['id_participante'])['ips_por_url'].agg(lambda x: np.median(x.tolist())).reset_index()\n",
    "# Renomeando a coluna da mediana\n",
    "valores_mediana_ips_porurl.columns = ['id_participante', 'mediana_ips_por_url']\n",
    "# Mesclando com o dataframe original\n",
    "df = pd.merge(df, valores_mediana_ips_porurl, on='id_participante', how='left')\n",
    "\n",
    "# Calcular desvio padrão de IPs por URL\n",
    "\n",
    "# Passo 1: Calcular a diferença quadrada entre lances por dispositivo e a média de lances de por dispositivo\n",
    "df['diferenca_quadrada'] = (df['ips_por_url'] - df['media_ips_porurl'])**2\n",
    "# Passo 2: Agrupar novamente pelo id_participante e calcular a média dos quadrados das diferenças\n",
    "desvios_quadraticos_medios = df.groupby('id_participante')['diferenca_quadrada'].mean()\n",
    "# Passo 3: Tirar a raiz quadrada dessa média\n",
    "std_ips_porurl = np.sqrt(desvios_quadraticos_medios)\n",
    "# Passo 4: Mapeando o desvio padrão correspondente para cada id_participante em df\n",
    "df['std_ips_porurl'] = df['id_participante'].map(std_ips_porurl)\n",
    "df = df.drop(columns = 'diferenca_quadrada', axis = 1)\n",
    "\n",
    "fim = time.time()\n",
    "print(f'Fim IPs - {fim - inicio} segundos')\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inicio País\n",
      "Fim Pais - 56.58388829231262 segundos\n"
     ]
    }
   ],
   "source": [
    "# País\n",
    "\n",
    "print('Inicio País')\n",
    "inicio = time.time()\n",
    "\n",
    "df['total_paises_participante'] = df.groupby(['id_participante'])['pais'].transform('nunique')\n",
    "\n",
    "# País por leilão\n",
    "\n",
    "df['paises_duplicados'] = df.groupby('id_participante')['pais'].transform(lambda x: x.duplicated(keep=False).sum())\n",
    "df['paises_por_leilao'] = df.groupby(['id_participante', 'leilao'])['pais'].transform('nunique')\n",
    "df['max_pais_porleilao'] = df.groupby(['id_participante'])['paises_por_leilao'].transform('max')\n",
    "df['media_pais_porleilao'] = df.groupby(['id_participante'])['paises_por_leilao'].transform('mean')\n",
    "\n",
    "## Calculando mediana de países por leilão\n",
    "# Agrupando e transformando as listas de lances por por dispositivo em cada grupo\n",
    "valores_mediana_paises_porleilao = df.groupby(['id_participante'])['paises_por_leilao'].agg(lambda x: np.median(x.tolist())).reset_index()\n",
    "# Renomeando a coluna da mediana\n",
    "valores_mediana_paises_porleilao.columns = ['id_participante', 'mediana_paises_por_leilao']\n",
    "# Mesclando com o dataframe original\n",
    "df = pd.merge(df, valores_mediana_paises_porleilao, on='id_participante', how='left')\n",
    "\n",
    "# Calcular desvio padrão de países por leilão\n",
    "\n",
    "# Passo 1: Calcular a diferença quadrada entre lances por dispositivo e a média de lances de por dispositivo\n",
    "df['diferenca_quadrada'] = (df['paises_por_leilao'] - df['media_pais_porleilao'])**2\n",
    "# Passo 2: Agrupar novamente pelo id_participante e calcular a média dos quadrados das diferenças\n",
    "desvios_quadraticos_medios = df.groupby('id_participante')['diferenca_quadrada'].mean()\n",
    "# Passo 3: Tirar a raiz quadrada dessa média\n",
    "std_paises_porleilao = np.sqrt(desvios_quadraticos_medios)\n",
    "# Passo 4: Mapeando o desvio padrão correspondente para cada id_participante em df\n",
    "df['std_paises_porleilao'] = df['id_participante'].map(std_paises_porleilao)\n",
    "df = df.drop(columns = 'diferenca_quadrada', axis = 1)\n",
    "\n",
    "\n",
    "# Lances por país\n",
    "\n",
    "df['lances_por_pais'] = df.groupby(['id_participante', 'pais'])['id_lance'].transform('nunique')\n",
    "df['max_lances_porpais'] = df.groupby(['id_participante'])['lances_por_pais'].transform('max')\n",
    "df['media_lances_porpais'] = df.groupby(['id_participante'])['lances_por_pais'].transform('mean')\n",
    "\n",
    "## Calculando mediana de lances por país\n",
    "# Agrupando e transformando as listas de lances por por dispositivo em cada grupo\n",
    "valores_mediana_lances_porpais = df.groupby(['id_participante'])['lances_por_pais'].agg(lambda x: np.median(x.tolist())).reset_index()\n",
    "# Renomeando a coluna da mediana\n",
    "valores_mediana_lances_porpais.columns = ['id_participante', 'mediana_lances_porpais']\n",
    "# Mesclando com o dataframe original\n",
    "df = pd.merge(df, valores_mediana_lances_porpais, on='id_participante', how='left')\n",
    "\n",
    "# Calcular desvio padrão de lances por país\n",
    "\n",
    "# Passo 1: Calcular a diferença quadrada entre lances por dispositivo e a média de lances de por dispositivo\n",
    "df['diferenca_quadrada'] = (df['lances_por_pais'] - df['media_lances_porpais'])**2\n",
    "# Passo 2: Agrupar novamente pelo id_participante e calcular a média dos quadrados das diferenças\n",
    "desvios_quadraticos_medios = df.groupby('id_participante')['diferenca_quadrada'].mean()\n",
    "# Passo 3: Tirar a raiz quadrada dessa média\n",
    "std_lances_porpais = np.sqrt(desvios_quadraticos_medios)\n",
    "# Passo 4: Mapeando o desvio padrão correspondente para cada id_participante em df\n",
    "df['std_lances_porpais'] = df['id_participante'].map(std_lances_porpais)\n",
    "df = df.drop(columns = 'diferenca_quadrada', axis = 1)\n",
    "\n",
    "\n",
    "# País por dispositivo\n",
    "\n",
    "df['paises_por_dispositivo'] = df.groupby(['id_participante', 'dispositivo'])['pais'].transform('nunique')\n",
    "df['max_pais_pordispositivo'] = df.groupby(['id_participante'])['paises_por_dispositivo'].transform('max')\n",
    "df['media_pais_pordispositivo'] = df.groupby(['id_participante'])['paises_por_dispositivo'].transform('mean')\n",
    "\n",
    "## Calculando mediana de países por leilão\n",
    "# Agrupando e transformando as listas de lances por por dispositivo em cada grupo\n",
    "valores_mediana_paises_pordispositivo = df.groupby(['id_participante'])['paises_por_dispositivo'].agg(lambda x: np.median(x.tolist())).reset_index()\n",
    "# Renomeando a coluna da mediana\n",
    "valores_mediana_paises_pordispositivo.columns = ['id_participante', 'mediana_paises_por_dispositivo']\n",
    "# Mesclando com o dataframe original\n",
    "df = pd.merge(df, valores_mediana_paises_pordispositivo, on='id_participante', how='left')\n",
    "\n",
    "# Calcular desvio padrão de países por leilão\n",
    "\n",
    "# Passo 1: Calcular a diferença quadrada entre lances por dispositivo e a média de lances de por dispositivo\n",
    "df['diferenca_quadrada'] = (df['paises_por_dispositivo'] - df['media_pais_pordispositivo'])**2\n",
    "# Passo 2: Agrupar novamente pelo id_participante e calcular a média dos quadrados das diferenças\n",
    "desvios_quadraticos_medios = df.groupby('id_participante')['diferenca_quadrada'].mean()\n",
    "# Passo 3: Tirar a raiz quadrada dessa média\n",
    "std_paises_pordispositivo = np.sqrt(desvios_quadraticos_medios)\n",
    "# Passo 4: Mapeando o desvio padrão correspondente para cada id_participante em df\n",
    "df['std_paises_pordispositivo'] = df['id_participante'].map(std_paises_pordispositivo)\n",
    "df = df.drop(columns = 'diferenca_quadrada', axis = 1)\n",
    "\n",
    "\n",
    "# País por url\n",
    "\n",
    "df['paises_por_url'] = df.groupby(['id_participante', 'url'])['pais'].transform('nunique')\n",
    "df['max_pais_porurl'] = df.groupby(['id_participante'])['paises_por_url'].transform('max')\n",
    "df['media_pais_porurl'] = df.groupby(['id_participante'])['paises_por_url'].transform('mean')\n",
    "\n",
    "## Calculando mediana de países por url\n",
    "# Agrupando e transformando as listas de lances por por dispositivo em cada grupo\n",
    "valores_mediana_paises_porurl = df.groupby(['id_participante'])['paises_por_url'].agg(lambda x: np.median(x.tolist())).reset_index()\n",
    "# Renomeando a coluna da mediana\n",
    "valores_mediana_paises_porurl.columns = ['id_participante', 'mediana_paises_por_url']\n",
    "# Mesclando com o dataframe original\n",
    "df = pd.merge(df, valores_mediana_paises_porurl, on='id_participante', how='left')\n",
    "\n",
    "# Calcular desvio padrão de países por url\n",
    "\n",
    "# Passo 1: Calcular a diferença quadrada entre lances por dispositivo e a média de lances de por dispositivo\n",
    "df['diferenca_quadrada'] = (df['paises_por_url'] - df['media_pais_porurl'])**2\n",
    "# Passo 2: Agrupar novamente pelo id_participante e calcular a média dos quadrados das diferenças\n",
    "desvios_quadraticos_medios = df.groupby('id_participante')['diferenca_quadrada'].mean()\n",
    "# Passo 3: Tirar a raiz quadrada dessa média\n",
    "std_paises_porurl = np.sqrt(desvios_quadraticos_medios)\n",
    "# Passo 4: Mapeando o desvio padrão correspondente para cada id_participante em df\n",
    "df['std_paises_porurl'] = df['id_participante'].map(std_paises_porurl)\n",
    "df = df.drop(columns = 'diferenca_quadrada', axis = 1)\n",
    "\n",
    "# País por ip\n",
    "\n",
    "df['paises_por_ip'] = df.groupby(['id_participante', 'ip'])['pais'].transform('nunique')\n",
    "df['max_pais_ip'] = df.groupby(['id_participante'])['paises_por_ip'].transform('max')\n",
    "df['media_pais_porip'] = df.groupby(['id_participante'])['paises_por_ip'].transform('mean')\n",
    "\n",
    "## Calculando mediana de países por ip\n",
    "# Agrupando e transformando as listas de lances por por dispositivo em cada grupo\n",
    "valores_mediana_paises_porip = df.groupby(['id_participante'])['paises_por_ip'].agg(lambda x: np.median(x.tolist())).reset_index()\n",
    "# Renomeando a coluna da mediana\n",
    "valores_mediana_paises_porip.columns = ['id_participante', 'mediana_paises_por_ip']\n",
    "# Mesclando com o dataframe original\n",
    "df = pd.merge(df, valores_mediana_paises_porip, on='id_participante', how='left')\n",
    "\n",
    "# Calcular desvio padrão de países por ip\n",
    "\n",
    "# Passo 1: Calcular a diferença quadrada entre lances por dispositivo e a média de lances de por dispositivo\n",
    "df['diferenca_quadrada'] = (df['paises_por_ip'] - df['media_pais_porip'])**2\n",
    "# Passo 2: Agrupar novamente pelo id_participante e calcular a média dos quadrados das diferenças\n",
    "desvios_quadraticos_medios = df.groupby('id_participante')['diferenca_quadrada'].mean()\n",
    "# Passo 3: Tirar a raiz quadrada dessa média\n",
    "std_paises_porip = np.sqrt(desvios_quadraticos_medios)\n",
    "# Passo 4: Mapeando o desvio padrão correspondente para cada id_participante em df\n",
    "df['std_paises_porip'] = df['id_participante'].map(std_paises_porip)\n",
    "df = df.drop(columns = 'diferenca_quadrada', axis = 1)\n",
    "\n",
    "\n",
    "fim = time.time()\n",
    "print(f'Fim Pais - {fim - inicio} segundos')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inicio URLs\n",
      "Fim URLs - 65.96945333480835 segundos\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# URL\n",
    "\n",
    "print('Inicio URLs')\n",
    "inicio = time.time()\n",
    "\n",
    "df['total_urls_participante'] = df.groupby(['id_participante'])['url'].transform('nunique')\n",
    "\n",
    "# URLs por leilão\n",
    "\n",
    "df['urls_duplicados'] = df.groupby('id_participante')['url'].transform(lambda x: x.duplicated(keep=False).sum())\n",
    "df['urls_por_leilao'] = df.groupby(['id_participante', 'leilao'])['url'].transform('nunique')\n",
    "df['max_urls_porleilao'] = df.groupby(['id_participante'])['urls_por_leilao'].transform('max')\n",
    "df['media_urls_porleilao'] = df.groupby(['id_participante'])['urls_por_leilao'].transform('mean')\n",
    "\n",
    "## Calculando mediana de URLs por leilao\n",
    "# Agrupando e transformando as listas de lances por por dispositivo em cada grupo\n",
    "valores_mediana_urls_porleilao = df.groupby(['id_participante'])['urls_por_leilao'].agg(lambda x: np.median(x.tolist())).reset_index()\n",
    "# Renomeando a coluna da mediana\n",
    "valores_mediana_urls_porleilao.columns = ['id_participante', 'mediana_urls_por_leilao']\n",
    "# Mesclando com o dataframe original\n",
    "df = pd.merge(df, valores_mediana_urls_porleilao, on='id_participante', how='left')\n",
    "\n",
    "# Calcular desvio padrão de URLs por leilão\n",
    "\n",
    "# Passo 1: Calcular a diferença quadrada entre lances por dispositivo e a média de lances de por dispositivo\n",
    "df['diferenca_quadrada'] = (df['urls_por_leilao'] - df['media_urls_porleilao'])**2\n",
    "# Passo 2: Agrupar novamente pelo id_participante e calcular a média dos quadrados das diferenças\n",
    "desvios_quadraticos_medios = df.groupby('id_participante')['diferenca_quadrada'].mean()\n",
    "# Passo 3: Tirar a raiz quadrada dessa média\n",
    "std_urls_porleilao = np.sqrt(desvios_quadraticos_medios)\n",
    "# Passo 4: Mapeando o desvio padrão correspondente para cada id_participante em df\n",
    "df['std_urls_porleilao'] = df['id_participante'].map(std_urls_porleilao)\n",
    "df = df.drop(columns = 'diferenca_quadrada', axis = 1)\n",
    "\n",
    "\n",
    "# Lances por URL\n",
    "\n",
    "df['lances_por_url'] = df.groupby(['id_participante', 'url'])['id_lance'].transform('nunique')\n",
    "df['max_lances_porurl'] = df.groupby(['id_participante'])['lances_por_url'].transform('max')\n",
    "df['media_lances_porurl'] = df.groupby(['id_participante'])['lances_por_url'].transform('mean')\n",
    "\n",
    "## Calculando mediana de lances por URL\n",
    "# Agrupando e transformando as listas de lances por por dispositivo em cada grupo\n",
    "valores_mediana_lances_porurl = df.groupby(['id_participante'])['lances_por_url'].agg(lambda x: np.median(x.tolist())).reset_index()\n",
    "# Renomeando a coluna da mediana\n",
    "valores_mediana_lances_porurl.columns = ['id_participante', 'mediana_lances_porurl']\n",
    "# Mesclando com o dataframe original\n",
    "df = pd.merge(df, valores_mediana_lances_porurl, on='id_participante', how='left')\n",
    "\n",
    "# Calcular desvio padrão de lances por URL\n",
    "\n",
    "# Passo 1: Calcular a diferença quadrada entre lances por dispositivo e a média de lances de por dispositivo\n",
    "df['diferenca_quadrada'] = (df['lances_por_url'] - df['media_lances_porurl'])**2\n",
    "# Passo 2: Agrupar novamente pelo id_participante e calcular a média dos quadrados das diferenças\n",
    "desvios_quadraticos_medios = df.groupby('id_participante')['diferenca_quadrada'].mean()\n",
    "# Passo 3: Tirar a raiz quadrada dessa média\n",
    "std_lances_porurl = np.sqrt(desvios_quadraticos_medios)\n",
    "# Passo 4: Mapeando o desvio padrão correspondente para cada id_participante em df\n",
    "df['std_lances_porurl'] = df['id_participante'].map(std_lances_porurl)\n",
    "df = df.drop(columns = 'diferenca_quadrada', axis = 1)\n",
    "\n",
    "\n",
    "# URLs por dispositivo\n",
    "df['urls_por_dispositivo'] = df.groupby(['id_participante', 'dispositivo'])['url'].transform('nunique')\n",
    "df['max_urls_pordispositivo'] = df.groupby(['id_participante'])['urls_por_dispositivo'].transform('max')\n",
    "df['media_urls_pordispositivo'] = df.groupby(['id_participante'])['urls_por_dispositivo'].transform('mean')\n",
    "\n",
    "## Calculando mediana de URLs por dispositivo\n",
    "# Agrupando e transformando as listas de lances por por dispositivo em cada grupo\n",
    "valores_mediana_urls_pordispositivo = df.groupby(['id_participante'])['urls_por_dispositivo'].agg(lambda x: np.median(x.tolist())).reset_index()\n",
    "# Renomeando a coluna da mediana\n",
    "valores_mediana_urls_pordispositivo.columns = ['id_participante', 'mediana_urls_por_dispositivo']\n",
    "# Mesclando com o dataframe original\n",
    "df = pd.merge(df, valores_mediana_urls_pordispositivo, on='id_participante', how='left')\n",
    "\n",
    "# Calcular desvio padrão de URLs por Dispositivo\n",
    "\n",
    "# Passo 1: Calcular a diferença quadrada entre lances por dispositivo e a média de lances de por dispositivo\n",
    "df['diferenca_quadrada'] = (df['urls_por_dispositivo'] - df['media_urls_pordispositivo'])**2\n",
    "# Passo 2: Agrupar novamente pelo id_participante e calcular a média dos quadrados das diferenças\n",
    "desvios_quadraticos_medios = df.groupby('id_participante')['diferenca_quadrada'].mean()\n",
    "# Passo 3: Tirar a raiz quadrada dessa média\n",
    "std_urls_pordispositivo = np.sqrt(desvios_quadraticos_medios)\n",
    "# Passo 4: Mapeando o desvio padrão correspondente para cada id_participante em df\n",
    "df['std_urls_pordispositivo'] = df['id_participante'].map(std_urls_pordispositivo)\n",
    "df = df.drop(columns = 'diferenca_quadrada', axis = 1)\n",
    "\n",
    "\n",
    "# URLs por pais\n",
    "df['urls_por_pais'] = df.groupby(['id_participante', 'pais'])['url'].transform('nunique')\n",
    "df['max_urls_porpais'] = df.groupby(['id_participante'])['urls_por_pais'].transform('max')\n",
    "df['media_urls_porpais'] = df.groupby(['id_participante'])['urls_por_pais'].transform('mean')\n",
    "\n",
    "## Calculando mediana de URLs por pais\n",
    "# Agrupando e transformando as listas de lances por por dispositivo em cada grupo\n",
    "valores_mediana_urls_porpais = df.groupby(['id_participante'])['urls_por_pais'].agg(lambda x: np.median(x.tolist())).reset_index()\n",
    "# Renomeando a coluna da mediana\n",
    "valores_mediana_urls_porpais.columns = ['id_participante', 'mediana_urls_por_pais']\n",
    "# Mesclando com o dataframe original\n",
    "df = pd.merge(df, valores_mediana_urls_porpais, on='id_participante', how='left')\n",
    "\n",
    "# Calcular desvio padrão de URLs por pais\n",
    "\n",
    "# Passo 1: Calcular a diferença quadrada entre lances por dispositivo e a média de lances de por dispositivo\n",
    "df['diferenca_quadrada'] = (df['urls_por_pais'] - df['media_urls_porpais'])**2\n",
    "# Passo 2: Agrupar novamente pelo id_participante e calcular a média dos quadrados das diferenças\n",
    "desvios_quadraticos_medios = df.groupby('id_participante')['diferenca_quadrada'].mean()\n",
    "# Passo 3: Tirar a raiz quadrada dessa média\n",
    "std_urls_porpais = np.sqrt(desvios_quadraticos_medios)\n",
    "# Passo 4: Mapeando o desvio padrão correspondente para cada id_participante em df\n",
    "df['std_urls_porpais'] = df['id_participante'].map(std_urls_porpais)\n",
    "df = df.drop(columns = 'diferenca_quadrada', axis = 1)\n",
    "\n",
    "\n",
    "# URLs por ip\n",
    "df['urls_por_ip'] = df.groupby(['id_participante', 'ip'])['url'].transform('nunique')\n",
    "df['max_urls_porip'] = df.groupby(['id_participante'])['urls_por_ip'].transform('max')\n",
    "df['media_urls_porip'] = df.groupby(['id_participante'])['urls_por_ip'].transform('mean')\n",
    "\n",
    "## Calculando mediana de URLs por ip\n",
    "# Agrupando e transformando as listas de lances por por dispositivo em cada grupo\n",
    "valores_mediana_urls_porip = df.groupby(['id_participante'])['urls_por_ip'].agg(lambda x: np.median(x.tolist())).reset_index()\n",
    "# Renomeando a coluna da mediana\n",
    "valores_mediana_urls_porip.columns = ['id_participante', 'mediana_urls_por_ip']\n",
    "# Mesclando com o dataframe original\n",
    "df = pd.merge(df, valores_mediana_urls_porip, on='id_participante', how='left')\n",
    "\n",
    "# Calcular desvio padrão de URLs por ip\n",
    "\n",
    "# Passo 1: Calcular a diferença quadrada entre lances por dispositivo e a média de lances de por dispositivo\n",
    "df['diferenca_quadrada'] = (df['urls_por_ip'] - df['media_urls_porip'])**2\n",
    "# Passo 2: Agrupar novamente pelo id_participante e calcular a média dos quadrados das diferenças\n",
    "desvios_quadraticos_medios = df.groupby('id_participante')['diferenca_quadrada'].mean()\n",
    "# Passo 3: Tirar a raiz quadrada dessa média\n",
    "std_urls_porip = np.sqrt(desvios_quadraticos_medios)\n",
    "# Passo 4: Mapeando o desvio padrão correspondente para cada id_participante em df\n",
    "df['std_urls_porip'] = df['id_participante'].map(std_urls_porip)\n",
    "df = df.drop(columns = 'diferenca_quadrada', axis = 1)\n",
    "\n",
    "fim = time.time()\n",
    "print(f'Fim URLs - {fim - inicio} segundos')\n",
    "\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "colunas_para_dropar = ['total_lances_nesseleilao', 'mercadoria_artigos esportivos', 'mercadoria_joias', 'mercadoria_móveis', 'mercadoria_equipamentos de escritório',\n",
    " 'mercadoria_bens domésticos', 'mercadoria_livros e música', 'mercadoria_computadores', 'mercadoria_peças de automóveis', 'mercadoria_vestuário',\n",
    " 'total_lances_pordispositivo', 'total_dispositivos_porleilao', 'total_dispositivos_porip', 'total_dispositivos_porurl', 'ips_por_leilao',\n",
    " 'lances_por_ip', 'ips_por_dispositivo', 'ips_por_pais', 'ips_por_url', 'paises_por_leilao', 'lances_por_pais', 'paises_por_dispositivo',\n",
    " 'paises_por_url', 'urls_por_leilao', 'lances_por_url', 'urls_por_dispositivo', 'urls_por_pais', 'urls_por_ip']\n",
    "\n",
    "df = df.drop(columns=colunas_para_dropar, axis = 1)\n",
    "df = df.drop_duplicates(subset='id_participante', keep='first')\n",
    "df = df.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inicio Lances vs todos\n",
      "Fim Lances vs Todos - 0.015793561935424805 segundos\n"
     ]
    }
   ],
   "source": [
    "# Ratios e novas estatísticas (Lances vs todos)\n",
    "\n",
    "\n",
    "# Lances por leilão\n",
    "\n",
    "print('Inicio Lances vs todos')\n",
    "inicio = time.time()\n",
    "\n",
    "# Ratio media / mediana Lances por leilão\n",
    "df['ratio_media_mediana_lances_porleilao'] = df['media_lances_porleilao'] / df['mediana_lances_porleilao']\n",
    "\n",
    "# Ratio entre desvio padrão e média\n",
    "df['ratio_std_media_lances_porleilao'] = df['std_lances_porleilao'] / df['media_lances_porleilao']\n",
    "\n",
    "# Combinação média e mediana focando em detecção de outliers\n",
    "df['comb_media_mediana_lances_porleilao'] = (0.5 * df['media_lances_porleilao']) + (0.5 * df['mediana_lances_porleilao'])\n",
    "\n",
    "# Lances por dipositivo\n",
    "\n",
    "# Ratio Max e média de lances por dispositivo\n",
    "df['ratio_max_media_lances_pordispositivo'] = df['max_lances_pordispositivo'] / df['media_lances_pordispositivo']\n",
    "\n",
    "# Diferença entre max e mediana de lances por dispositivo\n",
    "df['diff_max_mediana_lances_pordispositivo'] = df['max_lances_pordispositivo'] - df['mediana_lances_pordispositivo']\n",
    "df['var_percentual_media_mediana_lances_porleilao'] = (df['media_lances_porleilao'] - df['mediana_lances_pordispositivo']) / df['mediana_lances_pordispositivo']\n",
    "\n",
    "# Produto média e std de lances por dispositivo\n",
    "df['interacao_media_std_lances_pordispositivo'] = df['media_lances_pordispositivo'] * df['std_lances_pordispositivo']\n",
    "\n",
    "\n",
    "# Lances por IP\n",
    "# Ratio Max e média de lances por ip\n",
    "df['ratio_max_media_lances_porip'] = df['max_lances_porip'] / df['media_lances_porip']\n",
    "\n",
    "# Diferença entre max e mediana de lances por ip\n",
    "\n",
    "df['diff_max_mediana_lances_porip'] = df['max_lances_porip'] - df['mediana_lances_porip']\n",
    "df['var_percentual_media_mediana_lances_porip'] = (df['media_lances_porip'] - df['mediana_lances_porip']) / df['mediana_lances_porip']\n",
    "\n",
    "# Produto média e std de lances por ip\n",
    "df['interacao_media_std_lances_porip'] = df['media_lances_porip'] * df['std_lances_porip']\n",
    "\n",
    "# Ratio Max e média de ips por leilao\n",
    "df['ratio_max_media_lances_porip'] = df['max_lances_porip'] / df['media_lances_porip']\n",
    "\n",
    "\n",
    "# Lances por URL\n",
    "# Ratio Max e média de Lances por URL\n",
    "df['ratio_max_media_lances_porurl'] = df['max_lances_porurl'] / df['media_lances_porurl']\n",
    "\n",
    "# Diferença entre max e mediana de Lances por URL\n",
    "\n",
    "df['diff_max_mediana_lances_porurl'] = df['max_lances_porurl'] - df['mediana_lances_porurl']\n",
    "df['var_percentual_media_mediana_lances_porurl'] = (df['media_lances_porurl'] - df['mediana_lances_porurl']) / df['mediana_lances_porurl']\n",
    "\n",
    "# Produto média e std de Lances por URL\n",
    "df['interacao_media_std_lances_porurl'] = df['media_lances_porurl'] * df['std_lances_porurl']\n",
    "\n",
    "# Ratio Max e média de Lances por URL\n",
    "df['ratio_max_media_lances_porurl'] = df['max_lances_porurl'] / df['media_lances_porurl']\n",
    "\n",
    "\n",
    "# Lances por país\n",
    "# Ratio Max e média de Lances por país\n",
    "df['ratio_max_media_lances_porpais'] = df['max_lances_porpais'] / df['media_lances_porpais']\n",
    "\n",
    "# Diferença entre max e mediana de Lances por país\n",
    "\n",
    "df['diff_max_mediana_lances_porpais'] = df['max_lances_porpais'] - df['mediana_lances_porpais']\n",
    "df['var_percentual_media_mediana_lances_porpais'] = (df['media_lances_porpais'] - df['mediana_lances_porpais']) / df['mediana_lances_porpais']\n",
    "\n",
    "# Produto média e std de Lances por país\n",
    "df['interacao_media_std_lances_porurl'] = df['media_lances_porpais'] * df['std_lances_porpais']\n",
    "\n",
    "# Ratio Max e média de Lances por país\n",
    "df['ratio_max_media_lances_porpais'] = df['max_lances_porpais'] / df['media_lances_porpais']\n",
    "\n",
    "fim = time.time()\n",
    "print(f'Fim Lances vs Todos - {fim - inicio} segundos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inicio dispositivos vs todos\n",
      "Fim Dispositivos vs todos - 0.010057687759399414 segundos\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ratios e novas estatísticas (dispositivo vs todos)\n",
    "\n",
    "print('Inicio dispositivos vs todos')\n",
    "inicio = time.time()\n",
    "\n",
    "# Dispositivos por leilão\n",
    "\n",
    "# Ratio media / mediana Lances por leilão\n",
    "df['ratio_media_mediana_dispositivos_porleilao'] = df['media_dispositivos_porleilao'] / df['mediana_dispositivo_porleilao']\n",
    "\n",
    "# Ratio entre desvio padrão e média\n",
    "df['ratio_std_media_dispositivos_porleilao'] = df['std_dispositivos_porleilao'] / df['media_dispositivos_porleilao']\n",
    "\n",
    "# Combinação média e mediana focando em detecção de outliers\n",
    "df['comb_media_mediana_dispositivos_porleilao'] = (0.5 * df['media_dispositivos_porleilao']) + (0.5 * df['mediana_dispositivo_porleilao'])\n",
    "\n",
    "\n",
    "# Dispositivos por IP\n",
    "# Ratio Max e média de Dispositivos por IP\n",
    "df['ratio_max_media_dispositivos_porip'] = df['max_dispositivos_porip'] / df['media_dispositivos_porip']\n",
    "\n",
    "# Diferença entre max e mediana de Dispositivos por IP\n",
    "\n",
    "df['diff_max_mediana_dispositivos_porip'] = df['max_dispositivos_porip'] - df['mediana_dispositivo_porip']\n",
    "df['var_percentual_media_mediana_dispositivos_porip'] = (df['media_dispositivos_porip'] - df['mediana_dispositivo_porip']) / df['mediana_dispositivo_porip']\n",
    "\n",
    "# Produto média e std de Dispositivos por IP\n",
    "df['interacao_media_std_dispositivos_porip'] = df['media_dispositivos_porip'] * df['std_dispositivos_porip']\n",
    "\n",
    "# Ratio Max e média de Dispositivos por IP\n",
    "df['ratio_max_media_dispositivos_porip'] = df['max_dispositivos_porip'] / df['media_dispositivos_porip']\n",
    "\n",
    "\n",
    "# Dispositivos por URL\n",
    "# Ratio Max e média de Dispositivos por URL\n",
    "df['ratio_max_media_dispositivos_porurl'] = df['max_dispositivos_porurl'] / df['mediana_dispositivo_porurl']\n",
    "\n",
    "# Diferença entre max e mediana de Dispositivos por URL\n",
    "\n",
    "df['diff_max_mediana_dispositivos_porurl'] = df['max_dispositivos_porurl'] - df['mediana_dispositivo_porurl']\n",
    "df['var_percentual_media_mediana_dispositivos_porurl'] = (df['media_dispositivos_porurl'] - df['mediana_dispositivo_porurl']) / df['mediana_dispositivo_porurl']\n",
    "\n",
    "# Produto média e std de Dispositivos por URL\n",
    "df['interacao_media_std_dispositivos_porurl'] = df['media_dispositivos_porurl'] * df['std_dispositivos_porurl']\n",
    "\n",
    "# Ratio Max e média de Dispositivos por URL\n",
    "df['ratio_max_media_dispositivos_porurl'] = df['max_dispositivos_porurl'] / df['media_dispositivos_porurl']\n",
    "\n",
    "fim = time.time()\n",
    "print(f'Fim Dispositivos vs todos - {fim - inicio} segundos')\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inicio País vs todos\n",
      "Fim País vs todos - 0.016762495040893555 segundos\n"
     ]
    }
   ],
   "source": [
    "# Ratios e novas estatísticas (pais vs todos)\n",
    "\n",
    "print('Inicio País vs todos')\n",
    "inicio = time.time()\n",
    "\n",
    "\n",
    "# Ratio Max e média de Lances por país\n",
    "df['ratio_max_media_lances_porpais'] = df['max_lances_porpais'] / df['media_lances_porpais']\n",
    "\n",
    "# Diferença entre max e mediana de Lances por país\n",
    "\n",
    "df['diff_max_mediana_lances_porpais'] = df['max_lances_porpais'] - df['mediana_lances_porpais']\n",
    "df['var_percentual_media_mediana_lances_porpais'] = (df['media_lances_porpais'] - df['mediana_lances_porpais']) / df['mediana_lances_porpais']\n",
    "\n",
    "# Produto média e std de Lances por país\n",
    "df['interacao_media_std_lances_porurl'] = df['media_lances_porpais'] * df['std_lances_porpais']\n",
    "\n",
    "# Ratio Max e média de Lances por país\n",
    "df['ratio_max_media_lances_porpais'] = df['max_lances_porpais'] / df['media_lances_porpais']\n",
    "\n",
    "# Pais por leilão\n",
    "\n",
    "# Ratio media / mediana Pais por leilão\n",
    "df['ratio_media_mediana_pais_porleilao'] = df['media_pais_porleilao'] / df['mediana_paises_por_leilao']\n",
    "\n",
    "# Ratio entre desvio padrão e média\n",
    "df['ratio_std_media_pais_porleilao'] = df['std_paises_porleilao'] / df['media_pais_porleilao']\n",
    "\n",
    "# Combinação média e mediana focando em detecção de outliers\n",
    "df['comb_media_mediana_pais_porleilao'] = (0.5 * df['media_pais_porleilao']) + (0.5 * df['mediana_paises_por_leilao'])\n",
    "\n",
    "\n",
    "# Pais por dispositivo\n",
    "# Ratio Max e média de pais por dispositivo\n",
    "df['ratio_max_media_pais_pordispositivo'] = df['max_pais_pordispositivo'] / df['media_pais_pordispositivo']\n",
    "\n",
    "# Diferença entre max e mediana de Pais por dispositivo\n",
    "\n",
    "df['diff_max_mediana_pais_pordispositivo'] = df['max_pais_pordispositivo'] - df['mediana_paises_por_dispositivo']\n",
    "df['var_percentual_media_mediana_pais_pordispositivo'] = (df['media_pais_pordispositivo'] - df['mediana_paises_por_dispositivo']) / df['mediana_paises_por_dispositivo']\n",
    "\n",
    "# Produto média e std de Pais por dispositivo\n",
    "df['interacao_media_pais_pordispositivo'] = df['media_pais_pordispositivo'] * df['std_paises_pordispositivo']\n",
    "\n",
    "# Ratio Max e média de Pais por dispositivo\n",
    "df['ratio_max_media_pais_pordispositivo'] = df['max_pais_pordispositivo'] / df['media_pais_pordispositivo']\n",
    "\n",
    "\n",
    "# Pais por IP\n",
    "# Ratio Max e média de Pais por IP\n",
    "df['ratio_max_media_pais_porip'] = df['max_pais_ip'] / df['media_pais_porip']\n",
    "\n",
    "# Diferença entre max e mediana de Pais por IP\n",
    "\n",
    "df['diff_max_mediana_pais_porip'] = df['max_pais_ip'] - df['mediana_paises_por_ip']\n",
    "df['var_percentual_media_mediana_pais_porip'] = (df['media_pais_porip'] - df['mediana_paises_por_ip']) / df['mediana_paises_por_ip']\n",
    "\n",
    "# Produto média e std de Pais por IP\n",
    "df['interacao_media_std_pais_porip'] = df['media_pais_porip'] * df['std_paises_porip']\n",
    "\n",
    "# Ratio Max e média de Pais por IP\n",
    "df['ratio_max_media_pais_porip'] = df['max_pais_ip'] / df['media_pais_porip']\n",
    "\n",
    "\n",
    "# Pais por URL\n",
    "# Ratio Max e média de pais por URL\n",
    "df['ratio_max_media_pais_porurl'] = df['max_pais_porurl'] / df['media_pais_porurl']\n",
    "\n",
    "# Diferença entre max e mediana de pais por URL\n",
    "\n",
    "df['diff_max_mediana_pais_porurl'] = df['max_pais_porurl'] - df['mediana_paises_por_url']\n",
    "df['var_percentual_media_mediana_pais_porurl'] = (df['media_pais_porurl'] - df['mediana_paises_por_url']) / df['mediana_paises_por_url']\n",
    "\n",
    "# Produto média e std de pais por URL\n",
    "df['interacao_media_std_pais_porurl'] = df['media_pais_porurl'] * df['std_paises_porurl']\n",
    "\n",
    "# Ratio Max e média de Dispositivos por URL\n",
    "df['ratio_max_media_pais_porurl'] = df['max_pais_porurl'] / df['media_pais_porurl']\n",
    "\n",
    "fim = time.time()\n",
    "print(f'Fim País vs todos - {fim - inicio} segundos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inicio IPs vs todos\n",
      "Fim IPs vs todos - 0.014189958572387695 segundos\n"
     ]
    }
   ],
   "source": [
    "# Ratios e novas estatísticas (ips vs todos)\n",
    "\n",
    "print('Inicio IPs vs todos')\n",
    "inicio = time.time()\n",
    "\n",
    "# IPs por leilão\n",
    "\n",
    "# Ratio media / mediana Pais por leilão\n",
    "df['ratio_media_mediana_ips_porleilao'] = df['media_ips_porleilao'] / df['mediana_ips_porleilao']\n",
    "\n",
    "# Ratio entre desvio padrão e média\n",
    "df['ratio_std_media_ips_porleilao'] = df['std_ips_porleilao'] / df['media_ips_porleilao']\n",
    "\n",
    "# Combinação média e mediana focando em detecção de outliers\n",
    "df['comb_media_mediana_ips_porleilao'] = (0.5 * df['media_ips_porleilao']) + (0.5 * df['mediana_ips_porleilao'])\n",
    "\n",
    "\n",
    "# IPs por dispositivo\n",
    "# Ratio Max e média de pais por dispositivo\n",
    "df['ratio_max_media_ips_pordispositivo'] = df['max_ips_pordispositivo'] / df['media_ips_pordispositivo']\n",
    "\n",
    "# Diferença entre max e mediana de Pais por dispositivo\n",
    "\n",
    "df['diff_max_mediana_ips_pordispositivo'] = df['max_ips_pordispositivo'] - df['mediana_ips_por_dispositivo']\n",
    "df['var_percentual_media_mediana_ips_pordispositivo'] = (df['media_ips_pordispositivo'] - df['mediana_ips_por_dispositivo']) / df['mediana_ips_por_dispositivo']\n",
    "\n",
    "# Produto média e std de Pais por dispositivo\n",
    "df['interacao_media_ips_pordispositivo'] = df['media_ips_pordispositivo'] * df['std_ips_pordispositivo']\n",
    "\n",
    "# Ratio Max e média de Pais por dispositivo\n",
    "df['ratio_max_media_ips_pordispositivo'] = df['max_ips_pordispositivo'] / df['media_ips_pordispositivo']\n",
    "\n",
    "\n",
    "# IPs por país\n",
    "# Ratio Max e média de IPs por país\n",
    "df['ratio_max_media_ips_porpais'] = df['max_ips_porpais'] / df['media_ips_porpais']\n",
    "\n",
    "# Diferença entre max e mediana de IPs por país\n",
    "\n",
    "df['diff_max_mediana_ips_porpais'] = df['max_ips_porpais'] - df['mediana_ips_por_pais']\n",
    "df['var_percentual_media_mediana_ips_porpais'] = (df['media_ips_porpais'] - df['mediana_ips_por_pais']) / df['mediana_ips_por_pais']\n",
    "\n",
    "# Produto média e std de IPs por país\n",
    "df['interacao_media_std_ips_porpais'] = df['media_ips_porpais'] * df['std_ips_porpais']\n",
    "\n",
    "# Ratio Max e média de IPs por país\n",
    "df['ratio_max_media_ips_porpais'] = df['max_ips_porpais'] / df['media_ips_porpais']\n",
    "\n",
    "\n",
    "# IPs por URL\n",
    "# Ratio Max e média de pais por URL\n",
    "df['ratio_max_media_ips_porurl'] = df['max_ips_porurl'] / df['media_ips_porurl']\n",
    "\n",
    "# Diferença entre max e mediana de IPs por URL\n",
    "\n",
    "df['diff_max_mediana_ips_porurl'] = df['max_ips_porurl'] - df['mediana_ips_por_url']\n",
    "df['var_percentual_media_mediana_ips_porurl'] = (df['media_ips_porurl'] - df['mediana_ips_por_url']) / df['mediana_ips_por_url']\n",
    "\n",
    "# Produto média e std de IPs por URL\n",
    "df['interacao_media_std_ips_porurl'] = df['media_ips_porurl'] * df['std_ips_porurl']\n",
    "\n",
    "# Ratio Max e média de IPs por URL\n",
    "df['ratio_max_media_ips_porurl'] = df['max_ips_porurl'] / df['media_ips_porurl']\n",
    "\n",
    "fim = time.time()\n",
    "print(f'Fim IPs vs todos - {fim - inicio} segundos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inicio URLs vs todos\n",
      "Fim URLs vs todos - 0.01493525505065918 segundos\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ratios e novas estatísticas (URLs vs todos)\n",
    "\n",
    "print('Inicio URLs vs todos')\n",
    "inicio = time.time()\n",
    "\n",
    "# URLs por leilão\n",
    "\n",
    "# Ratio media / mediana URL por leilão\n",
    "df['ratio_media_mediana_urls_porleilao'] = df['media_urls_porleilao'] / df['mediana_urls_por_leilao']\n",
    "\n",
    "# Ratio entre desvio padrão e média\n",
    "df['ratio_std_media_urls_porleilao'] = df['std_urls_porleilao'] / df['media_urls_porleilao']\n",
    "\n",
    "# Combinação média e mediana focando em detecção de outliers\n",
    "df['comb_media_mediana_urls_porleilao'] = (0.5 * df['media_urls_porleilao']) + (0.5 * df['mediana_urls_por_leilao'])\n",
    "\n",
    "\n",
    "# URLs por dispositivo\n",
    "# Ratio Max e média de pais por dispositivo\n",
    "df['ratio_max_media_urls_pordispositivo'] = df['max_urls_pordispositivo'] / df['media_urls_pordispositivo']\n",
    "\n",
    "# Diferença entre max e mediana de URL por dispositivo\n",
    "\n",
    "df['diff_max_mediana_urls_pordispositivo'] = df['max_urls_pordispositivo'] - df['mediana_urls_por_dispositivo']\n",
    "df['var_percentual_media_mediana_urls_pordispositivo'] = (df['media_urls_pordispositivo'] - df['mediana_urls_por_dispositivo']) / df['mediana_urls_por_dispositivo']\n",
    "\n",
    "# Produto média e std de URLs por dispositivo\n",
    "df['interacao_media_urls_pordispositivo'] = df['media_urls_pordispositivo'] * df['std_urls_pordispositivo']\n",
    "\n",
    "# Ratio Max e média de URLs por dispositivo\n",
    "df['ratio_max_media_urls_pordispositivo'] = df['max_urls_pordispositivo'] / df['media_urls_pordispositivo']\n",
    "\n",
    "\n",
    "# URLs por país\n",
    "# Ratio Max e média de IPs por país\n",
    "df['ratio_max_media_urls_porpais'] = df['max_urls_porpais'] / df['media_urls_porpais']\n",
    "\n",
    "# Diferença entre max e mediana de IPs por país\n",
    "\n",
    "df['diff_max_mediana_urls_porpais'] = df['max_urls_porpais'] - df['mediana_urls_por_pais']\n",
    "df['var_percentual_media_mediana_urls_porpais'] = (df['media_urls_porpais'] - df['mediana_urls_por_pais']) / df['mediana_urls_por_pais']\n",
    "\n",
    "# Produto média e std de IPs por país\n",
    "df['interacao_media_std_urls_porpais'] = df['media_urls_porpais'] * df['std_urls_porpais']\n",
    "\n",
    "# Ratio Max e média de IPs por país\n",
    "df['ratio_max_media_urls_porpais'] = df['max_urls_porpais'] / df['media_urls_porpais']\n",
    "\n",
    "\n",
    "# URLs por IP\n",
    "# Ratio Max e média de URLs por IP\n",
    "df['ratio_max_media_urls_porip'] = df['max_urls_porip'] / df['media_urls_porip']\n",
    "\n",
    "# Diferença entre max e mediana de URLs por IP\n",
    "\n",
    "df['diff_max_mediana_urls_porip'] = df['max_urls_porip'] - df['mediana_urls_por_ip']\n",
    "df['var_percentual_media_mediana_urls_porip'] = (df['media_urls_porip'] - df['mediana_urls_por_ip']) / df['mediana_urls_por_ip']\n",
    "\n",
    "# Produto média e std de URLs por IP\n",
    "df['interacao_media_std_urls_porip'] = df['media_urls_porip'] * df['std_urls_porip']\n",
    "\n",
    "# Ratio Max e média de URLs por IP\n",
    "df['ratio_max_media_urls_porip'] = df['max_urls_porip'] / df['media_urls_porip']\n",
    "\n",
    "fim = time.time()\n",
    "print(f'Fim URLs vs todos - {fim - inicio} segundos')\n",
    "\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "colunas_para_dropar = ['id_lance', 'leilao', 'mercadoria', 'dispositivo', 'tempo', 'pais', 'ip', 'url']\n",
    "df.drop(columns=colunas_para_dropar, axis=1, inplace=True)\n",
    "df = df.drop_duplicates(subset='id_participante', keep='first')\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "df_lances = df.merge(df_tempo, on='id_participante', how='left')\n",
    "df_lances = df_lances.merge(df_entropia, on='id_participante', how='left')\n",
    "\n",
    "df_lances.to_csv(diretorio_destino, index= False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id_participante',\n",
       " 'total_lances_participante',\n",
       " 'leiloes_participados',\n",
       " 'media_lances_porleilao',\n",
       " 'max_lances_leilao',\n",
       " 'mediana_lances_porleilao',\n",
       " 'std_lances_porleilao',\n",
       " 'qtde_mercadorias_participante',\n",
       " 'qtde_lance_artigos esportivos',\n",
       " 'qtde_lance_joias',\n",
       " 'qtde_lance_móveis',\n",
       " 'qtde_lance_equipamentos de escritório',\n",
       " 'qtde_lance_bens domésticos',\n",
       " 'qtde_lance_livros e música',\n",
       " 'qtde_lance_computadores',\n",
       " 'qtde_lance_peças de automóveis',\n",
       " 'qtde_lance_vestuário',\n",
       " 'total_dispositivos_participante',\n",
       " 'dispositivos_duplicados',\n",
       " 'max_lances_pordispositivo',\n",
       " 'media_lances_pordispositivo',\n",
       " 'mediana_lances_pordispositivo',\n",
       " 'std_lances_pordispositivo',\n",
       " 'max_dispositivos_porleilao',\n",
       " 'media_dispositivos_porleilao',\n",
       " 'mediana_dispositivo_porleilao',\n",
       " 'std_dispositivos_porleilao',\n",
       " 'max_dispositivos_porip',\n",
       " 'media_dispositivos_porip',\n",
       " 'mediana_dispositivo_porip',\n",
       " 'std_dispositivos_porip',\n",
       " 'max_dispositivos_porurl',\n",
       " 'media_dispositivos_porurl',\n",
       " 'mediana_dispositivo_porurl',\n",
       " 'std_dispositivos_porurl',\n",
       " 'total_ips_participante',\n",
       " 'ips_duplicados',\n",
       " 'max_ips_porleilao',\n",
       " 'media_ips_porleilao',\n",
       " 'mediana_ips_porleilao',\n",
       " 'std_ips_porleilao',\n",
       " 'max_lances_porip',\n",
       " 'media_lances_porip',\n",
       " 'mediana_lances_porip',\n",
       " 'std_lances_porip',\n",
       " 'max_ips_pordispositivo',\n",
       " 'media_ips_pordispositivo',\n",
       " 'mediana_ips_por_dispositivo',\n",
       " 'std_ips_pordispositivo',\n",
       " 'max_ips_porpais',\n",
       " 'media_ips_porpais',\n",
       " 'mediana_ips_por_pais',\n",
       " 'std_ips_porpais',\n",
       " 'max_ips_porurl',\n",
       " 'media_ips_porurl',\n",
       " 'mediana_ips_por_url',\n",
       " 'std_ips_porurl',\n",
       " 'total_paises_participante',\n",
       " 'paises_duplicados',\n",
       " 'max_pais_porleilao',\n",
       " 'media_pais_porleilao',\n",
       " 'mediana_paises_por_leilao',\n",
       " 'std_paises_porleilao',\n",
       " 'max_lances_porpais',\n",
       " 'media_lances_porpais',\n",
       " 'mediana_lances_porpais',\n",
       " 'std_lances_porpais',\n",
       " 'max_pais_pordispositivo',\n",
       " 'media_pais_pordispositivo',\n",
       " 'mediana_paises_por_dispositivo',\n",
       " 'std_paises_pordispositivo',\n",
       " 'max_pais_porurl',\n",
       " 'media_pais_porurl',\n",
       " 'mediana_paises_por_url',\n",
       " 'std_paises_porurl',\n",
       " 'paises_por_ip',\n",
       " 'max_pais_ip',\n",
       " 'media_pais_porip',\n",
       " 'mediana_paises_por_ip',\n",
       " 'std_paises_porip',\n",
       " 'total_urls_participante',\n",
       " 'urls_duplicados',\n",
       " 'max_urls_porleilao',\n",
       " 'media_urls_porleilao',\n",
       " 'mediana_urls_por_leilao',\n",
       " 'std_urls_porleilao',\n",
       " 'max_lances_porurl',\n",
       " 'media_lances_porurl',\n",
       " 'mediana_lances_porurl',\n",
       " 'std_lances_porurl',\n",
       " 'max_urls_pordispositivo',\n",
       " 'media_urls_pordispositivo',\n",
       " 'mediana_urls_por_dispositivo',\n",
       " 'std_urls_pordispositivo',\n",
       " 'max_urls_porpais',\n",
       " 'media_urls_porpais',\n",
       " 'mediana_urls_por_pais',\n",
       " 'std_urls_porpais',\n",
       " 'max_urls_porip',\n",
       " 'media_urls_porip',\n",
       " 'mediana_urls_por_ip',\n",
       " 'std_urls_porip',\n",
       " 'ratio_media_mediana_lances_porleilao',\n",
       " 'ratio_std_media_lances_porleilao',\n",
       " 'comb_media_mediana_lances_porleilao',\n",
       " 'ratio_max_media_lances_pordispositivo',\n",
       " 'diff_max_mediana_lances_pordispositivo',\n",
       " 'var_percentual_media_mediana_lances_porleilao',\n",
       " 'interacao_media_std_lances_pordispositivo',\n",
       " 'ratio_max_media_lances_porip',\n",
       " 'diff_max_mediana_lances_porip',\n",
       " 'var_percentual_media_mediana_lances_porip',\n",
       " 'interacao_media_std_lances_porip',\n",
       " 'ratio_max_media_lances_porurl',\n",
       " 'diff_max_mediana_lances_porurl',\n",
       " 'var_percentual_media_mediana_lances_porurl',\n",
       " 'interacao_media_std_lances_porurl',\n",
       " 'ratio_max_media_lances_porpais',\n",
       " 'diff_max_mediana_lances_porpais',\n",
       " 'var_percentual_media_mediana_lances_porpais',\n",
       " 'ratio_media_mediana_dispositivos_porleilao',\n",
       " 'ratio_std_media_dispositivos_porleilao',\n",
       " 'comb_media_mediana_dispositivos_porleilao',\n",
       " 'ratio_max_media_dispositivos_porip',\n",
       " 'diff_max_mediana_dispositivos_porip',\n",
       " 'var_percentual_media_mediana_dispositivos_porip',\n",
       " 'interacao_media_std_dispositivos_porip',\n",
       " 'ratio_max_media_dispositivos_porurl',\n",
       " 'diff_max_mediana_dispositivos_porurl',\n",
       " 'var_percentual_media_mediana_dispositivos_porurl',\n",
       " 'interacao_media_std_dispositivos_porurl',\n",
       " 'ratio_media_mediana_pais_porleilao',\n",
       " 'ratio_std_media_pais_porleilao',\n",
       " 'comb_media_mediana_pais_porleilao',\n",
       " 'ratio_max_media_pais_pordispositivo',\n",
       " 'diff_max_mediana_pais_pordispositivo',\n",
       " 'var_percentual_media_mediana_pais_pordispositivo',\n",
       " 'interacao_media_pais_pordispositivo',\n",
       " 'ratio_max_media_pais_porip',\n",
       " 'diff_max_mediana_pais_porip',\n",
       " 'var_percentual_media_mediana_pais_porip',\n",
       " 'interacao_media_std_pais_porip',\n",
       " 'ratio_max_media_pais_porurl',\n",
       " 'diff_max_mediana_pais_porurl',\n",
       " 'var_percentual_media_mediana_pais_porurl',\n",
       " 'interacao_media_std_pais_porurl',\n",
       " 'ratio_media_mediana_ips_porleilao',\n",
       " 'ratio_std_media_ips_porleilao',\n",
       " 'comb_media_mediana_ips_porleilao',\n",
       " 'ratio_max_media_ips_pordispositivo',\n",
       " 'diff_max_mediana_ips_pordispositivo',\n",
       " 'var_percentual_media_mediana_ips_pordispositivo',\n",
       " 'interacao_media_ips_pordispositivo',\n",
       " 'ratio_max_media_ips_porpais',\n",
       " 'diff_max_mediana_ips_porpais',\n",
       " 'var_percentual_media_mediana_ips_porpais',\n",
       " 'interacao_media_std_ips_porpais',\n",
       " 'ratio_max_media_ips_porurl',\n",
       " 'diff_max_mediana_ips_porurl',\n",
       " 'var_percentual_media_mediana_ips_porurl',\n",
       " 'interacao_media_std_ips_porurl',\n",
       " 'ratio_media_mediana_urls_porleilao',\n",
       " 'ratio_std_media_urls_porleilao',\n",
       " 'comb_media_mediana_urls_porleilao',\n",
       " 'ratio_max_media_urls_pordispositivo',\n",
       " 'diff_max_mediana_urls_pordispositivo',\n",
       " 'var_percentual_media_mediana_urls_pordispositivo',\n",
       " 'interacao_media_urls_pordispositivo',\n",
       " 'ratio_max_media_urls_porpais',\n",
       " 'diff_max_mediana_urls_porpais',\n",
       " 'var_percentual_media_mediana_urls_porpais',\n",
       " 'interacao_media_std_urls_porpais',\n",
       " 'ratio_max_media_urls_porip',\n",
       " 'diff_max_mediana_urls_porip',\n",
       " 'var_percentual_media_mediana_urls_porip',\n",
       " 'interacao_media_std_urls_porip',\n",
       " 'qtde_lances_pico',\n",
       " 'qtde_lances_fora_pico',\n",
       " 'porcentagem_lances_pico',\n",
       " 'porcentagem_lances_fora_pico',\n",
       " 'porcentagem_lances_quartil_1',\n",
       " 'porcentagem_lances_quartil_2',\n",
       " 'porcentagem_lances_quartil_3',\n",
       " 'porcentagem_lances_quartil_4',\n",
       " 'std_lances_por_quartil',\n",
       " 'media_diftempo_porusuario',\n",
       " 'mediana_difs_tempo_participante',\n",
       " 'std_difstempo_porlance',\n",
       " 'qtde_lances_simultaneos',\n",
       " 'tem_lance_simultaneo',\n",
       " 'entropia_ip',\n",
       " 'entropia_pais',\n",
       " 'entropia_dispositivo',\n",
       " 'entropia_url',\n",
       " 'entropia_pais_ip',\n",
       " 'entropia_dispositivo_ip',\n",
       " 'entropia_dispositivo_url',\n",
       " 'entropia_dispositivo_pais',\n",
       " 'entropia_url_pais']"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lances.columns.tolist()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
